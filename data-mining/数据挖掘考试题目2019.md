数据挖掘考试：一共10个解答题，每个题10分
欢迎大家一起添加合适的答案

# 一，知识发现
## 知识发现的过程？
1.	数据清洗（消除噪声和删除不一致数据）
2.	数据集成（多种数据源可以组合在一起）
3.	数据转换
4.	数据规约
5.	数据挖掘
6.	结果评价
## 知识发现与数据挖掘的联系？
数据挖掘是知识发现的一个步骤。

# 二，数据预处理
## 数据预处理的哪些方面，每一个方面涉及哪些处理方法？

### 数据清理
- 处理空缺值的方法：
- 忽略元组
- 人工填写空缺值
- 使用固定值
- 使用属性平均值
- 使用最有可能值

### 处理噪声数据的方法：（如何平滑数据）
- 分箱
- 聚类
- 计算机和人工检查相结合
- 回归

### 数据集成
将多个数据源中的数据结合起来存放在一个一致的数据存贮中：
- 实体识别：实体和模式的匹配
- 冗余：某个属性可以由别的属性推出。
- 相关分析
- 相关性rA,B
    > rA,B>0,正相关。A随B的值得增大而增大
    > rA,B>0,正相关。AB无关
    > rA,B>0,正相关。A随B的值得增大而减少

- 重复：同一数据存储多次
- 数据值冲突的检测和处理

### 数据变换
- 平滑
- 聚集
- 数据概化
- 规范化
- 属性构造(特征构造)
- 最小-最大规范化
- 小数定标规范化
- 属性构造
> 由给定的属性构造和添加新的属性，以帮助提高精度和对高维数据结构的理解

### 数据规约
- 数据立方体聚集
- 维规约
- 数据压缩
- 数值规约


# 三，关联分析
## Apriori算法，描述，特点，优缺点，如何解决缺点？
Apriori算法采用迭代的方法，先搜索出候选1项集以及对应的支持度，剪枝去掉低于支持度的候选1项集，得到频繁1项集。然后对剩下的频繁1项集进行连接，得到候选2项集，筛选去掉低于支持度的候选2项集，得到频繁2项集。如此迭代下去，直到无法找到频繁k+1集为止，对应的频繁k项集的集合便是算法的输出结果。

特点：
只能处理分类变量，无法处理数值型变量；

优点：
适合稀疏数据集。
算法原理简单，易实现。
适合事务数据库的关联规则挖掘。

缺点：
可能产生庞大的候选集。
算法需多次遍历数据集，算法效率低，耗时。
对候选项集的支持度计算繁琐

优化方法：
基于散列的技术
事务压缩
划分
抽样
动态项集计数
FP-growth算法，描述，特点，优缺点，如何解决缺点？

特点：
适用数据类型：标称型数据(离散型数据)。

优点： 一般要快于Apriori。(通常性能要好两个数量级以上)
缺点： 实现比较困难，在某些数据集上性能会下降。

# 四，分类
## KNN算法：特点？
优点：精度高、对异常值不敏感、无数据输入假定
缺点：计算复杂度高、空间复杂度高
适用数据范围：数值型和标称型

## 决策树：特点？如何量化属性的重要性程度？量化方法的优缺点？决策树为什么在损失一定精度的情况下还要进行剪枝？剪枝后会有什么影响？



剪枝是因为决策树会出现过度拟合的问题。
（算法生成的决策树非常详细并且庞大，每个属性都被详细地加以考虑，决策树的树叶节点所覆盖的训练样本都是“纯”的。因此用这个决策树来对训练样本进行分类的话，你会发现对于训练样本而言，这个树表现完好，误差率极低且能够正确得对训练样本集中的样本进行分类。训练样本中的错误数据也会被决策树学习，成为决策树的部分，但是对于测试数据的表现就没有想象的那么好，或者极差，这就是所谓的过拟合 参考来源）

## 贝叶斯算法：什么时候使用贝叶斯算法？贝叶斯算法的特点是什么？什么时候使用贝叶斯网络？

## BP网络算法：为何要使用梯度下降法来训练网络？

## 对分类算法的评价？


# 五，聚类

## 聚类方法，特点？




---


# 六，数据仓库「不考」


参考来源：
[GitHub_nanfengpo][1]


  [1]: https://github.com/nanfengpo/MachineLearning/tree/master/docs
